##########################################################################
# Apache Kafka - KRaft Mode Configuration (Single-Node)
#
# This configuration runs Kafka in KRaft mode without ZooKeeper.
# Designed for use with the official apache/kafka Docker image.
# Suitable for a single-node production deployment.
##########################################################################

# --------------------------------------------------------------------------
# KRaft Mode Settings
# --------------------------------------------------------------------------
# In KRaft mode, Kafka manages its own metadata without ZooKeeper.
# process.roles defines what this node does:
#   - broker: handles client produce/consume requests
#   - controller: manages cluster metadata (replaces ZooKeeper)
# For a single-node setup, this node acts as both broker and controller.
process.roles=broker,controller

# Unique identifier for this node within the cluster. Must be a positive
# integer and unique across all nodes in the cluster.
node.id=1

# Defines the set of controller nodes that form the Raft quorum for
# metadata management. Format: {node.id}@{host}:{controller-port}
# For a single-node setup, only this node participates in the quorum.
controller.quorum.voters=1@kafka:9093

# The listener name used for communication between controllers.
# Must match one of the entries in listener.security.protocol.map.
controller.listener.names=CONTROLLER

# --------------------------------------------------------------------------
# Listeners
# --------------------------------------------------------------------------
# listeners: the addresses and ports Kafka binds to on this host.
#   - PLAINTEXT on port 9092: for client produce/consume traffic
#   - CONTROLLER on port 9093: for internal KRaft controller communication
# Binding to 0.0.0.0 allows connections from any network interface,
# which is necessary inside a Docker container.
listeners=SASL_PLAINTEXT://0.0.0.0:9092,SASL_SSL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093

# advertised.listeners: the addresses clients use to connect to this broker.
# Must be resolvable by clients. In Docker/Kubernetes, this is typically the
# service or container hostname. Do NOT include the CONTROLLER listener here.
#   - SASL_PLAINTEXT on 9092: internal (Docker network)
#   - SASL_SSL on 9094: external (SSL + SASL authentication)
advertised.listeners=SASL_PLAINTEXT://kafka:9092,SASL_SSL://95.217.61.39:9094

# The listener used for inter-broker communication (replication, etc.).
inter.broker.listener.name=SASL_PLAINTEXT

# Maps listener names to security protocols.
# CONTROLLER uses PLAINTEXT (internal only), client listener uses SASL_PLAINTEXT.
listener.security.protocol.map=CONTROLLER:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# --------------------------------------------------------------------------
# SASL Authentication
# --------------------------------------------------------------------------
# SASL/PLAIN mechanism for username/password authentication.
# Credentials are defined in kafka-server-jaas.conf.
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.inter.broker.protocol=PLAIN

# --------------------------------------------------------------------------
# SSL/TLS Configuration
# --------------------------------------------------------------------------
# Self-signed certificate (CN=95.217.61.39, SAN=IP:95.217.61.39).
# SASL_SSL listener on port 9094 for external encrypted connections.
ssl.keystore.type=PKCS12
ssl.keystore.location=/etc/kafka/certs/kafka.keystore.p12
ssl.keystore.password=KafkaSSL2026
ssl.key.password=KafkaSSL2026
ssl.truststore.type=PKCS12
ssl.truststore.location=/etc/kafka/certs/kafka.truststore.p12
ssl.truststore.password=KafkaSSL2026

# --------------------------------------------------------------------------
# Log Directories
# --------------------------------------------------------------------------
# log.dirs: where Kafka stores topic partition data (the actual messages).
# In Docker, mount a persistent volume here to survive container restarts.
log.dirs=/var/lib/kafka/data

# metadata.log.dir: where KRaft stores its metadata log (cluster state,
# topic configurations, etc.). Should be on reliable storage. Keeping it
# separate from log.dirs is recommended for performance and clarity.
metadata.log.dir=/var/lib/kafka/metadata

# --------------------------------------------------------------------------
# Topic Defaults
# --------------------------------------------------------------------------
# Default number of partitions for auto-created topics. More partitions
# allow higher parallelism but consume more file handles and memory.
# 3 is a reasonable default for moderate workloads.
num.partitions=3

# Default replication factor for new topics. Set to 1 for single-node
# deployments. In multi-node clusters, use 3 for high availability.
default.replication.factor=1

# Minimum number of in-sync replicas that must acknowledge a write for
# it to be considered successful (when acks=all). Set to 1 for single-node.
# In multi-node clusters, use 2 with replication.factor=3.
min.insync.replicas=1

# Replication settings for internal Kafka topics. These must be 1 for a
# single-node cluster since there is only one broker to host replicas.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

# --------------------------------------------------------------------------
# Log Retention
# --------------------------------------------------------------------------
# How long Kafka retains messages before they become eligible for deletion.
# 168 hours = 7 days. Adjust based on your data retention requirements.
log.retention.hours=168

# Maximum size of a partition log before old segments are deleted.
# -1 means no size limit; retention is controlled only by time (above).
log.retention.bytes=-1

# Maximum size of a single log segment file. When a segment reaches this
# size, a new segment is created. 1 GB is the default and works well
# for most workloads.
log.segment.bytes=1073741824

# How often (in milliseconds) the log cleaner checks whether any log
# segments are eligible for deletion. 300000 ms = 5 minutes.
log.retention.check.interval.ms=300000

# --------------------------------------------------------------------------
# Performance Tuning
# --------------------------------------------------------------------------
# Number of threads handling network requests (reading from and writing
# to the network socket). Increase for higher connection counts.
num.network.threads=3

# Number of threads performing disk I/O (reading from and writing to
# log segment files). Increase if disk throughput is a bottleneck.
num.io.threads=8

# Socket buffer sizes for send and receive operations. These affect
# throughput for large messages. 100 KB is a reasonable starting point.
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400

# Maximum size of a request that the broker will accept. This limits the
# maximum message batch size. 100 MB allows large batches while preventing
# a single request from consuming excessive memory.
socket.request.max.bytes=104857600

# --------------------------------------------------------------------------
# Group Coordinator
# --------------------------------------------------------------------------
# Delay (in milliseconds) before the group coordinator performs the first
# consumer group rebalance. This gives time for more consumers to join
# before triggering a rebalance, reducing unnecessary rebalance storms
# during application startup. 3000 ms = 3 seconds.
group.initial.rebalance.delay.ms=3000

# --------------------------------------------------------------------------
# Topic Auto-Creation
# --------------------------------------------------------------------------
# When set to false, topics must be created explicitly before a producer
# or consumer can use them. This prevents accidental topic creation from
# typos or misconfigured clients, which is strongly recommended for
# production environments.
auto.create.topics.enable=true
